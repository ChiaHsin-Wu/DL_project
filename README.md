# Sentiment Classification with RNN, LSTM and GRU
## 簡介
本專案針對美妝保養品產業，利用 Kaggle 上 Sephora 產品與評論資料，透過深度學習模型預測新品上市前可能引發的使用者回饋類型。目標在於幫助品牌方在產品開發階段提早掌握潛在優缺點，降低上市風險並優化行銷策略。

## 資料敘述
資料來源為公開資料集「Sephora Products and Skincare Reviews」，由 Kaggle 使用者 NADY INKY 整理提供。資料於 2023 年 3 月透過 Python 爬蟲自 Sephora 官方網站擷取，包含超過 8,000 筆產品資訊與約 100 萬則使用者評論。產品資訊涵蓋名稱、品牌、成分、價格及多層級分類；評論則包含用戶評分、推薦意見及完整文字內容，資料完整且豐富，適合用於產品優缺點分析與預測。

## 分析過程
(一) 原始資料處理
針對產品資訊與評論資料進行欄位篩選與清理，並將評論分為正面與負面，使用 TF-IDF 和 Sentence-BERT 進行關鍵詞語意分群，定義多個正負面主題標籤，再對評論文本詞幹化處理，進行多標籤分類標記。最後將產品資料與評論標籤合併，形成訓練及測試資料集。

(二) 模型設計與比較
建立基本 RNN、雙向 LSTM 及雙向 GRU 三種模型，皆以 Fasttext 詞向量作為嵌入層，並使用 Sigmoid 輸出多標籤預測。以 Micro-F1 分數選出最佳模型後，進一步加入 L1 正則化或 Dropout，以減少過度擬合的情況。

## 結果
(一) 正面資料
在正面資料中，三種單層循環神經網路模型皆有傾向將產品分類為類別 1 或 2 的現象，顯示資料本身存在類別不平衡的情況。其中，以 GRU 為核心的模型在 Testing micro 分數上表現最佳，約為 0.848，代表其在整體預測較為準確。進一步針對 GRU 模型加入 L1 正規化與 Dropout 以減緩過度擬合問題，但整體結果未優於原始 GRU 模型。雖然加入 L1 正規化的模型在驗證階段（val_loss）有下降，最終測試表現仍略低於原始版本。

(二) 負面資料
在負面資料中，同樣觀察到明顯的分類不平衡現象，其中以 RNN 模型在 Testing micro 分數上表現最佳，約為 0.790，表示整體預測能力較穩定。針對過度擬合問題，加入 L1 正規化與 Dropout 機制後，可發現兩者皆有助於降低過度擬合的情況，而 L1 正規化的成效最佳，約為 0.796。
